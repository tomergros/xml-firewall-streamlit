<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>326542</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="cyber-attacks-classification-using-distilbert" class="cell markdown" data-papermill="{&quot;duration&quot;:1.6794e-2,&quot;end_time&quot;:&quot;2023-07-16T14:05:47.650263&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.633469&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1><strong>Cyber Attacks Classification using DistilBERT</strong></h1>
</section>
<div class="cell markdown" data-papermill="{&quot;duration&quot;:1.5795e-2,&quot;end_time&quot;:&quot;2023-07-16T14:05:47.681559&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.665764&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<blockquote>
<p><strong>Presented by:</strong></p>
<p>Tomer Grossman &amp; Oriel Somech</p>
<p><strong>Academic Advisor:</strong></p>
<p>Dr. Guy Leshem</p>
<p><strong>Computer Science Department</strong></p>
<p><strong>CLB - Ramat Gan Academic Center</strong></p>
</blockquote>
</div>
<div class="cell markdown" data-papermill="{&quot;duration&quot;:1.5342e-2,&quot;end_time&quot;:&quot;2023-07-16T14:05:47.712533&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.697191&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<p><img src="1efd9651-0fd1-48f2-9156-5aad7aad0fdd.jpg" alt="xml-project-logo.jpg" /></p>
</div>
<div class="cell markdown" data-papermill="{&quot;duration&quot;:1.5136e-2,&quot;end_time&quot;:&quot;2023-07-16T14:05:47.744729&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.729593&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<blockquote>
<p><strong>This notebook demonstrates how to use the DistilBERT model, a powerful natural language processing (NLP) model, to classify different types of cyber attacks. The dataset used contains examples of SQL injection, Denial of Service (DoS), and XML External Entity (XXE) attacks, along with a "none" category for non-attacks. The notebook covers the steps of data preprocessing, model training, evaluation, and saving the trained model for future use. It includes visualizations such as training and validation accuracy plots and a confusion matrix to assess the model's performance. By following this notebook, you will gain insights into training an NLP model to classify cyber attacks and learn how to apply it in real-world scenarios.</strong></p>
</blockquote>
</div>
<div class="cell markdown" data-papermill="{&quot;duration&quot;:1.5173e-2,&quot;end_time&quot;:&quot;2023-07-16T14:05:47.775091&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.759918&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<ul>
<li><h1 id="model-we-use---distilbert"><strong>Model We Use - DistilBERT</strong></h1></li>
</ul>
</div>
<div class="cell markdown" data-papermill="{&quot;duration&quot;:1.5167e-2,&quot;end_time&quot;:&quot;2023-07-16T14:05:47.805569&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.790402&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<p><img src="98e51f06-0772-4cf8-acd7-6e2f0423dc47.png" alt="image.png" /></p>
<blockquote>
<p><strong>Examlpe of the DistilBERT model architecture</strong></p>
<p>DistilBERT is a smaller and faster version of the BERT model. It retains BERT's ability to understand the meaning of words in context but with fewer layers and reduced size.</p>
<p>DistilBERT is trained using a technique called knowledge distillation from a larger BERT (Bidirectional Encoder Representations from Transformers) model. Knowledge distillation involves transferring the knowledge learned by a larger, more complex model to a smaller and more efficient model.</p>
</blockquote>
</div>
<div class="cell markdown" data-papermill="{&quot;duration&quot;:1.4567e-2,&quot;end_time&quot;:&quot;2023-07-16T14:05:47.834841&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.820274&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<ul>
<li><h1 id="sql-injection-example"><strong>SQL Injection Example</strong></h1>
<p><img src="fc4b966d-0ffa-435a-98ab-629f2e721256.png" alt="image.png" /></p>
<blockquote>
<p>A XML with SQL Injection attack can inject source code into a application such that it can be interpreted and run as a valid SQL query to perform a database operation with malicious intent.</p>
<p>For example, XML SQL attacks can be launched to gain unauthorized access to the contents of a database or to manipulate the stored data.</p>
<p>XML SQL Injection attacks are not only common, but can also be very harmful and costly.</p>
</blockquote></li>
</ul>
</div>
<div class="cell markdown" data-papermill="{&quot;duration&quot;:1.4547e-2,&quot;end_time&quot;:&quot;2023-07-16T14:05:47.864053&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.849506&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<ul>
<li><h1 id="xxe---xml-external-entity-example"><strong>XXE - XML External Entity Example</strong></h1>
<p><img src="01227fde-29db-47a4-8c92-77c979c31082.png" alt="image.png" /></p>
<blockquote>
<p>XML external entity injection (also known as XXE) is a web security vulnerability that allows an attacker to interfere with an application's processing of XML data. It often allows an attacker to view files on the application server filesystem, and to interact with any back-end or external systems that the application itself can access.</p>
</blockquote></li>
</ul>
</div>
<div class="cell markdown" data-papermill="{&quot;duration&quot;:1.4519e-2,&quot;end_time&quot;:&quot;2023-07-16T14:05:47.893555&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.879036&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<ul>
<li><h1 id="dos---denial-of-service-example"><strong>DOS - Denial Of Service Example</strong></h1>
<p><img src="eccf9fff-4b0b-4336-923a-ad718e8e91cc.png" alt="image.png" /></p>
<blockquote>
<p>A denial-of-service attack (DoS attack) is a cyber-attack where the attacker looks to make a machine or network resource unavailable.</p>
<p>One type of especially nasty XML DoS attack is the XML bomb—a block of XML that is both well-formed and valid according to the rules of an XML schema but which crashes or hangs a program when that program attempts to parse it.</p>
</blockquote></li>
</ul>
</div>
<section id="1-import-dependencies" class="cell markdown" data-papermill="{&quot;duration&quot;:1.4629e-2,&quot;end_time&quot;:&quot;2023-07-16T14:05:47.922873&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.908244&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>1. <strong>Import Dependencies</strong></h1>
</section>
<div class="cell code" data-execution_count="1" data-_cell_guid="b1076dfc-b9ad-4769-8c92-a6c4dae69d19" data-_uuid="8f2839f25d086af736a60e9eeb907d3b93b6e0e5" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-16T14:05:47.955248Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-16T14:05:47.954494Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-16T14:06:06.237419Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-16T14:06:06.236507Z&quot;}" data-papermill="{&quot;duration&quot;:18.302746,&quot;end_time&quot;:&quot;2023-07-16T14:06:06.240273&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:05:47.937527&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Dataset</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> DistilBertForSequenceClassification, DistilBertTokenizer</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.23.5
  warnings.warn(f&quot;A NumPy version &gt;={np_minversion} and &lt;{np_maxversion}&quot;
/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: [&#39;/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so&#39;]
caused by: [&#39;/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE&#39;]
  warnings.warn(f&quot;unable to load libtensorflow_io_plugins.so: {e}&quot;)
/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: [&#39;/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so&#39;]
caused by: [&#39;/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE&#39;]
  warnings.warn(f&quot;file system plugins are not loaded: {e}&quot;)
</code></pre>
</div>
</div>
<section id="2-load-and-preprocess-data" class="cell markdown" data-papermill="{&quot;duration&quot;:1.5849e-2,&quot;end_time&quot;:&quot;2023-07-16T14:06:06.272931&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:06:06.257082&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1><strong>2. Load and Preprocess Data</strong></h1>
</section>
<div class="cell code" data-execution_count="2" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-16T14:06:06.306636Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-16T14:06:06.306330Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-16T14:06:07.544738Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-16T14:06:07.543859Z&quot;}" data-papermill="{&quot;duration&quot;:1.257988,&quot;end_time&quot;:&quot;2023-07-16T14:06:07.546949&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:06:06.288961&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the device for training (CPU or GPU if available)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&#39;cuda&#39;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;/kaggle/input/injections/injections_dataset.csv&#39;</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the dataset into train, validation, and test sets</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>train_texts, temp_texts, train_labels, temp_labels <span class="op">=</span> train_test_split(</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;text&#39;</span>], df[<span class="st">&#39;label&#39;</span>], test_size<span class="op">=</span><span class="fl">0.4</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>valid_texts, test_texts, valid_labels, test_labels <span class="op">=</span> train_test_split(</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    temp_texts, temp_labels, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a custom Dataset class for loading the data</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CyberAttacksDataset(Dataset):</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, texts, labels, tokenizer, max_length):</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.texts <span class="op">=</span> texts</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labels <span class="op">=</span> labels</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tokenizer <span class="op">=</span> tokenizer</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_length <span class="op">=</span> max_length</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.texts)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> <span class="bu">str</span>(<span class="va">self</span>.texts.iloc[idx])  <span class="co"># Use .iloc[idx] to access by index</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="va">self</span>.labels.iloc[idx]  <span class="co"># Use .iloc[idx] to access by index</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>        encoding <span class="op">=</span> <span class="va">self</span>.tokenizer.encode_plus(</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>            text,</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>            add_special_tokens<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>            truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>            max_length<span class="op">=</span><span class="va">self</span>.max_length,</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">&#39;max_length&#39;</span>,</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>            return_tensors<span class="op">=</span><span class="st">&#39;pt&#39;</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        input_ids <span class="op">=</span> encoding[<span class="st">&#39;input_ids&#39;</span>].squeeze()</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        attention_mask <span class="op">=</span> encoding[<span class="st">&#39;attention_mask&#39;</span>].squeeze()</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;input_ids&#39;</span>: input_ids,</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;attention_mask&#39;</span>: attention_mask,</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;label&#39;</span>: label</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the tokenizer</span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> DistilBertTokenizer.from_pretrained(<span class="st">&#39;distilbert-base-uncased&#39;</span>)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the maximum sequence length for tokenization</span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>max_length <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Dataset instances for train, validation, and test sets</span></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> CyberAttacksDataset(train_texts, train_labels, tokenizer, max_length)</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>valid_dataset <span class="op">=</span> CyberAttacksDataset(valid_texts, valid_labels, tokenizer, max_length)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> CyberAttacksDataset(test_texts, test_labels, tokenizer, max_length)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb4"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;dca0525d69f64666a6e0b84d808eff7a&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb5"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8b53da113b974b128a395865731d1198&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb6"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;c8ee6a3b56e6445ab9aeb4b7ed265203&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<section id="3-model-training" class="cell markdown" data-papermill="{&quot;duration&quot;:1.6124e-2,&quot;end_time&quot;:&quot;2023-07-16T14:06:07.579002&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:06:07.562878&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1><strong>3. Model Training</strong></h1>
</section>
<div class="cell code" data-execution_count="3" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-16T14:06:07.611765Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-16T14:06:07.611401Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-16T14:21:13.688911Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-16T14:21:13.688003Z&quot;}" data-papermill="{&quot;duration&quot;:906.096352,&quot;end_time&quot;:&quot;2023-07-16T14:21:13.691066&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:06:07.594714&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the device for training (CPU or GPU if available)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&#39;cuda&#39;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the batch size and number of training epochs</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data loaders for train and validation sets</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>valid_loader <span class="op">=</span> DataLoader(valid_dataset, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the DistilBERT model for sequence classification</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DistilBertForSequenceClassification.from_pretrained(</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;distilbert-base-uncased&#39;</span>,</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span><span class="dv">4</span>  <span class="co"># 4 categories: SQL injection, DoS, XXE, none</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>model.to(device)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the optimizer and loss function</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span><span class="fl">2e-5</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>train_losses <span class="op">=</span> []</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>valid_losses <span class="op">=</span> []</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>train_accs <span class="op">=</span> []</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>valid_accs <span class="op">=</span> []</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    train_acc <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        input_ids <span class="op">=</span> batch[<span class="st">&#39;input_ids&#39;</span>].to(device)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        attention_mask <span class="op">=</span> batch[<span class="st">&#39;attention_mask&#39;</span>].to(device)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> batch[<span class="st">&#39;label&#39;</span>].to(device)</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>            input_ids<span class="op">=</span>input_ids,</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>            attention_mask<span class="op">=</span>attention_mask,</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>labels</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> outputs.logits</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        _, preds <span class="op">=</span> torch.<span class="bu">max</span>(logits, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(logits, labels)</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">+=</span> loss.item()</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>        train_acc <span class="op">+=</span> accuracy_score(labels.cpu(), preds.cpu())</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">/=</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>    train_acc <span class="op">/=</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>    train_losses.append(train_loss)</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>    train_accs.append(train_acc)</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validation</span></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>    valid_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>    valid_acc <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> valid_loader:</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>            input_ids <span class="op">=</span> batch[<span class="st">&#39;input_ids&#39;</span>].to(device)</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>            attention_mask <span class="op">=</span> batch[<span class="st">&#39;attention_mask&#39;</span>].to(device)</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> batch[<span class="st">&#39;label&#39;</span>].to(device)</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>                input_ids<span class="op">=</span>input_ids,</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>                attention_mask<span class="op">=</span>attention_mask,</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>                labels<span class="op">=</span>labels</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> outputs.logits</span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a>            _, preds <span class="op">=</span> torch.<span class="bu">max</span>(logits, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(logits, labels)</span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a>            valid_loss <span class="op">+=</span> loss.item()</span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a>            valid_acc <span class="op">+=</span> accuracy_score(labels.cpu(), preds.cpu())</span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a>    valid_loss <span class="op">/=</span> <span class="bu">len</span>(valid_loader)</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>    valid_acc <span class="op">/=</span> <span class="bu">len</span>(valid_loader)</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>    valid_losses.append(valid_loss)</span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a>    valid_accs.append(valid_acc)</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Train Loss: </span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss"> | Train Acc: </span><span class="sc">{</span>train_acc<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Valid Loss: </span><span class="sc">{</span>valid_loss<span class="sc">:.4f}</span><span class="ss"> | Valid Acc: </span><span class="sc">{</span>valid_acc<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;-&#39;</span> <span class="op">*</span> <span class="dv">30</span>)</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training and validation accuracy</span></span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>plt.plot(train_accs, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a>plt.plot(valid_accs, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>)</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Training &amp; Validation Accuracy&#39;</span>)</span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb8"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;3e5642709f8a4835a868f02d7f86f201&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: [&#39;vocab_layer_norm.bias&#39;, &#39;vocab_transform.weight&#39;, &#39;vocab_transform.bias&#39;, &#39;vocab_projector.bias&#39;, &#39;vocab_layer_norm.weight&#39;]
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#39;pre_classifier.bias&#39;, &#39;pre_classifier.weight&#39;, &#39;classifier.weight&#39;, &#39;classifier.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Epoch 1/2
Train Loss: 0.0320 | Train Acc: 0.9928
Valid Loss: 0.0044 | Valid Acc: 0.9989
------------------------------
Epoch 2/2
Train Loss: 0.0033 | Train Acc: 0.9992
Valid Loss: 0.0037 | Valid Acc: 0.9990
------------------------------
</code></pre>
</div>
<div class="output display_data">
<p><img src="d7f3d9dd35de78c57606fe5949e2e09ee651d8fb.png" /></p>
</div>
</div>
<section id="4-evaluation" class="cell markdown" data-papermill="{&quot;duration&quot;:1.7437e-2,&quot;end_time&quot;:&quot;2023-07-16T14:21:13.726737&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:21:13.709300&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1><strong>4. Evaluation</strong></h1>
</section>
<div class="cell code" data-execution_count="4" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-16T14:21:13.763809Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-16T14:21:13.762851Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-16T14:22:02.654473Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-16T14:22:02.653522Z&quot;}" data-papermill="{&quot;duration&quot;:48.912345,&quot;end_time&quot;:&quot;2023-07-16T14:22:02.656505&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:21:13.744160&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data loader for the test set</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation on test set</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>test_acc <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> []</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>true_labels <span class="op">=</span> []</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> test_loader:</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>        input_ids <span class="op">=</span> batch[<span class="st">&#39;input_ids&#39;</span>].to(device)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        attention_mask <span class="op">=</span> batch[<span class="st">&#39;attention_mask&#39;</span>].to(device)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> batch[<span class="st">&#39;label&#39;</span>].to(device)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>            input_ids<span class="op">=</span>input_ids,</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>            attention_mask<span class="op">=</span>attention_mask,</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>labels</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> outputs.logits</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        _, preds <span class="op">=</span> torch.<span class="bu">max</span>(logits, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(logits, labels)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        test_loss <span class="op">+=</span> loss.item()</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>        test_acc <span class="op">+=</span> accuracy_score(labels.cpu(), preds.cpu())</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>        predictions.extend(preds.cpu().tolist())</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>        true_labels.extend(labels.cpu().tolist())</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">/=</span> <span class="bu">len</span>(test_loader)</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>test_acc <span class="op">/=</span> <span class="bu">len</span>(test_loader)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Test Loss: </span><span class="sc">{</span>test_loss<span class="sc">:.4f}</span><span class="ss"> | Test Acc: </span><span class="sc">{</span>test_acc<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(true_labels, predictions)</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>plt.imshow(cm, interpolation<span class="op">=</span><span class="st">&#39;nearest&#39;</span>, cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Confusion Matrix&#39;</span>)</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Predicted&#39;</span>)</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;True&#39;</span>)</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="dv">4</span>), [<span class="st">&#39;SQL injection&#39;</span>, <span class="st">&#39;DoS&#39;</span>, <span class="st">&#39;XXE&#39;</span>, <span class="st">&#39;None&#39;</span>])</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(<span class="dv">4</span>), [<span class="st">&#39;SQL injection&#39;</span>, <span class="st">&#39;DoS&#39;</span>, <span class="st">&#39;XXE&#39;</span>, <span class="st">&#39;None&#39;</span>])</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Test Loss: 0.0040 | Test Acc: 0.9987
</code></pre>
</div>
<div class="output display_data">
<p><img src="d20590abaa0353dcb6c89d559a08f4d98ae9f3e7.png" /></p>
</div>
</div>
<section id="5-save-the-trained-model" class="cell markdown" data-papermill="{&quot;duration&quot;:1.8072e-2,&quot;end_time&quot;:&quot;2023-07-16T14:22:02.693247&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:22:02.675175&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1><strong>5. Save the Trained Model</strong></h1>
</section>
<div class="cell code" data-execution_count="5" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-16T14:22:02.730303Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-16T14:22:02.729982Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-16T14:22:03.293222Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-16T14:22:03.292042Z&quot;}" data-papermill="{&quot;duration&quot;:0.58439,&quot;end_time&quot;:&quot;2023-07-16T14:22:03.295429&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:22:02.711039&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the trained model</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">&#39;./saved_model&#39;</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(output_dir):</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    os.makedirs(output_dir)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>model.save_pretrained(output_dir)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>tokenizer.save_pretrained(output_dir)</span></code></pre></div>
<div class="output execute_result" data-execution_count="5">
<pre><code>(&#39;./saved_model/tokenizer_config.json&#39;,
 &#39;./saved_model/special_tokens_map.json&#39;,
 &#39;./saved_model/vocab.txt&#39;,
 &#39;./saved_model/added_tokens.json&#39;)</code></pre>
</div>
</div>
<section id="finally-we-use-the-trained-model-in-a-software-thus-the-model-will-be-implemented-inside-and-classify-cyber-attacks-in-xml-files" class="cell markdown" data-papermill="{&quot;duration&quot;:1.7944e-2,&quot;end_time&quot;:&quot;2023-07-16T14:22:03.331147&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-16T14:22:03.313203&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Finally we use the trained model in a software, thus the model will be implemented inside and classify cyber attacks in XML files</h1>
</section>
</body>
</html>
